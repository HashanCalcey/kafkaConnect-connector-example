#
# Copyright 2018 Confluent Inc.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# name=gcs-sink
# connector.class=io.confluent.connect.gcs.GcsSinkConnector
# tasks.max=1
# topics=gcs_topic

# gcs.bucket.name=kafkapoc
# gcs.part.size=5242880
# flush.size=3

# gcs.credentials.path=/home/calcey/Downloads/googleServiceKey/My-Project-16b4d96303c4.json

# storage.class=io.confluent.connect.gcs.storage.GcsStorage
# format.class=io.confluent.connect.gcs.format.avro.AvroFormat
# format.class=io.confluent.connect.gcs.format.json.JsonFormat
# partitioner.class=io.confluent.connect.storage.partitioner.DefaultPartitioner

# schema.compatibility=NONE

# Example values when using a time-based partitioner
#partitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner
# For instance, set partition duration to 1 hour
#partition.duration.ms=3600000
#path.format='year'=YYYY_'month'=MM_'day'=dd_'hour'=HH
#locale=en
#timezone=America/Los_Angeles
# Use a deterministic partitioner based on Kafka record timestamps
#timestamp.extractor=Record
# For example, rotate a file every 15 minutes
#rotate.interval.ms=900000
# Also, set size-based rotation to a high value
#flush.size=1000000

# Or use a field based partitioner
#partitioner.class=io.confluent.connect.storage.partitioner.FieldPartitioner
#partition.field.name=


#############################
# CONFLUENT LICENSE SETTINGS
#############################

# Confluent will issue a license key to each subscriber. The license key will be a short snippet
# of text that you can copy and paste. Without the license key, you can use this connector for a
# 30-day trial period. If you are a subscriber, please contact Confluent Support for more
# information.
# confluent.license=

# Name of the Kafka topic used for Confluent Platform configuration, including licensing
# information.
#confluent.topic=_confluent-command

# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster
# used for licensing. All servers in the cluster will be discovered from the initial connection.
# This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers
# are just used for the initial connection to discover the full cluster membership (which may
# change dynamically), this list need not contain the full set of servers (you may want more than
# one, though, in case a server is down).
# This is a required config property
# confluent.topic.bootstrap.servers=localhost:9092

# The replication factor for the Kafka topic used for Confluent Platform configuration, including
# licensing information. This is used only if the topic does not already exist, and the default
# of 3 is appropriate for production use. If you are using a development environment with less
# than 3 brokers, you must set this to the number of brokers (often 1).
#confluent.topic.replication.factor=3
# confluent.topic.replication.factor=1

# In secured clusters, add any security configs to the Kafka clients used on confluent.topic by 
# using the prefixes, such as confluent.topic. 
# or confluent.topic.producer. and confluent.topic.consumer. 
# if settings differ between the producer and the consumer that read the confluent.topic

### Standard connector configuration

## Fill in your values in these:

# Unique name for the connector.
# Attempting to register again with the same name will fail.
name=my-gcs-connector

## These must have exactly these values:

# The Java class for the connector
connector.class=io.aiven.kafka.connect.gcs.GcsSinkConnector

# The key converter for this connector
# (must be set to ByteArrayConverter)
key.converter=org.apache.kafka.connect.converters.ByteArrayConverter

# The value converter for this connector
# (must be set to ByteArrayConverter)
value.converter=org.apache.kafka.connect.converters.ByteArrayConverter

# A comma-separated list of topics to use as input for this connector
# Also a regular expression version `topics.regex` is supported.
# See https://kafka.apache.org/documentation/#connect_configuring
topics=server1.dbo.students


### Connector-specific configuration
### Fill in you values

# The name of the GCS bucket to use
# Required.
# gcs.bucket.name=my-gcs-bucket
gcs.bucket.name=kafkapoc
# GCP credentials as a JSON object.
# Required.
# Note that the connector supports passing GCP credentials
# as a file, but this is not supported on Aiven platform.
gcs.credentials.json={
  "type": "service_account",
  "project_id": "hashanrctest",
  "private_key_id": "16b4d96303c486707a97427c485b10c52decf66b",
  "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQDTVpIgOxgVqEom\nB5IP7tpI93EItZEPiDmoPMseD2ZYBsP90tlMzMDyg48mB6z4a5W96DelPJPO0XAA\nCTCGc6meKAdPFAJBEAS6gHYVNJ3JB2hV0WL6fQQ+qq1yckM//u2e2+dGw+Qx9iQ5\nko7zqGmq3hJ6waP72xZkQ4S8bRRbiGPNgSjExjkaI+lwyt1OdENiZj4VGo27Im31\n++OcKtFkgyr9BAZzPcDuzjI+hxKMp7rNloRwP05abyfycS7ibnksjQdYpeJeMSl9\naNHX0+/urLJsO+wB0c9iGxXYtWGThXJvACftAr6moRGO1VP1Lu3o2A2dxBEPLvZQ\nV4UIeIibAgMBAAECggEAZ+j12hEUK3neU0p/n4PiIeQ/2HdlhoyFRNn3SKVrvbY9\n4WwtWZyG9faHiLxXaKGFM6Wczoq1ZggGGI5sJH90E4Y86b29yf21RXnqFU0Uk4Yn\n36IfF2gmkSVcOJxDwpB2hxg6Y8nnRkVu1DviO50/rzqXPXI+TZQQM2YbOoYrb0D/\n+1zC14Apm+MHCCSctcIWctfycPZrb2kAIp+a65LGXp6+AF3WXxypxSUSr6XD9XMF\nBuPLykqd9RkLWIZBX9PMxb0pp2jPSXojuW/OKQGRE3be5eJoDHopEG/44fg/l5Jt\n8y0iwkUVeLHq7daOiNYQpg18TWmXdyFUnUq6jWP7QQKBgQD5qay9jTNbIoh+EwSt\nWfnAQcgrf21zw2IVwxtEjKip2uefEhR56sTUl8MZINl07ozKYrpfQY6wfcLQlS5A\nOT/KPbBC4eqSOBfdf7YHkqcRI/WmqRBJbIr52TEVuLtOac9EfvDn/4BElgCPn83L\ny1BmAQDK1cZPgoPDpvLMh9eN+wKBgQDYs9wv4mxNjJqLz5NyM86Oj28eFtdXBAW4\nf6gNG7a7hOVCiEG25vk42S+Ilt65gGaBNYl1w53nsZr2e57+2fP91bvnwdxFFGUQ\nL+mIKA1qtGAIjgClrrSwMLZhs44snnU4TwFW1DUO8v2Kz0+B4FAkrRroGBDpWrTg\nYdFHBz0N4QKBgQDBIEfHuVpovSXooL2Ve2x/FGPLgh8g1ZsiSnLlbAlsmzFhE5NT\nXBA2g88fuRF+KqouRID2/rdqP15cC4pjk+WMhHu8wRW7Vjjf1tLwuLkTwUVdTpqS\nsawv6ZrWurfpyF/VFH02eaa3Z3G3qF6BrxzaSxxZy1REXSmgR5y6KrrL0QKBgQCG\nfPF9Ile2tTlA5b2LVc2uuiPrF5/jWBK40zkXkYiRzkN+TBQEkEpB1sBiU8e8doyn\nSfOai6HXJmmW6VfesKN1eI1aovyyPpsONb4Ii1rwSyuCg6axLMDkzAaUkhv9YwY6\nwQWCvsaDFZj26fxdDTqP2ILnYfA08t9oliyMmVhx4QKBgQCqZf8ceYkyzxdOQsY4\nQaYtXO4N8nw8UewSGvNmns6/M0nodqnjIDIuNbsltEYQdfm2jdzOP/MHP/KYhnYB\n5VIZ3ZASDGBOmtptVUKt3fKMv0EEjzSbMWPAYNpVDw7P8u/Ps3kH0JpAJVUZSnP4\nqnV4wcXO6GlZ0/76rEtg2gdf7A==\n-----END PRIVATE KEY-----\n",
  "client_email": "1098920535127@developer.gserviceaccount.com",
  "client_id": "1098920535127.apps.googleusercontent.com",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/1098920535127%40developer.gserviceaccount.com"
}
# gcs.credentials.path=/home/calcey/Downloads/googleServiceKey/My-Project-16b4d96303c4.json

# The set of the fields that are to be output, comma separated.
# Supported values are: `key`, `value`, `offset`, and `timestamp`.
# Optional, the default is `value`.
format.output.fields=key,value,offset,timestamp

# The prefix to be added to the name of each file put on GCS.
# See the GCS naming requirements https://cloud.google.com/storage/docs/naming
# Optional, the default is empty.
file.name.prefix=some-prefix/

# The compression type used for files put on GCS.
# The supported values are: `gzip`, `none`.
# Optional, the default is `none`.
file.compression.type=gzip